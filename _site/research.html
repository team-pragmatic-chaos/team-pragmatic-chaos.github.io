<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Bringing Photos to Life using Deep Learning</title>
  <meta name="description" content="Deep Videos (CSCI 599 Project)
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/research.html">
  <link rel="alternate" type="application/rss+xml" title="Team Pragmatic Chaos Blog" href="http://yourdomain.com/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Team Pragmatic Chaos Blog</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/research.html">Bringing Photos to Life using Deep Learning</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Bringing Photos to Life using Deep Learning</h1>
    <p class="post-meta"><time datetime="2017-11-22T05:24:39+00:00" itemprop="datePublished">Nov 22, 2017</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Consider the problem of a self driving car. What if, the car could predict the motion of objects around it using a sequence of static image frames ? It would definitely make our lives a lot safer wouldn’t it?
Have you ever faced a situation where you’re watching your favorite sport on TV and the video freezes for an instant, and you miss out on an important moment your friends are going to talk about at work tomorrow?</p>

<p>In this blog we present an approach to tackle the above problems using deep learning.  The goal of this project is to predict future video frames  by learning the dynamics of a given scene. This blog post is aimed at providing a high level summary of approaches and models that worked for us along with results. If you’d like to take a look at all the things we tried, including things that didn’t work, and the challenges and pitfalls associated with every thing that goes on in a deep learning model, you can look at our struggles here[link to log page].</p>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
  <li><a href="#data-source">Data Source</a>
    <ul>
      <li><a href="#datasets">Datasets</a></li>
      <li><a href="#batch-generation">Batch Generation</a></li>
      <li><a href="#selection-at-an-interval">Selection at an interval</a></li>
    </ul>
  </li>
  <li><a href="#sequence-to-sequence-model">Sequence to Sequence Model</a>
    <ul>
      <li><a href="#architecture">Architecture</a></li>
      <li><a href="#training-and-testing">Training and Testing</a></li>
      <li><a href="#results">Results</a></li>
      <li><a href="#problems">Problems</a></li>
    </ul>
  </li>
  <li><a href="#autoencoder-model">Autoencoder Model</a>
    <ul>
      <li><a href="#architecture-1">Architecture</a></li>
      <li><a href="#training-and-testing-1">Training and Testing</a></li>
      <li><a href="#results-1">Results</a></li>
      <li><a href="#problems-1">Problems</a></li>
    </ul>
  </li>
  <li><a href="#multi-scale-model">Multi-Scale Model</a>
    <ul>
      <li><a href="#architecture-2">Architecture</a></li>
      <li><a href="#model-twicks">Model tweaks</a></li>
      <li><a href="#training-and-testing-2">Training and Testing</a></li>
      <li><a href="#graphs-2">Graphs</a></li>
      <li><a href="#results-2">Results</a></li>
      <li><a href="#evaluation">Evaluation</a></li>
      <li><a href="#problems-2">Problems</a></li>
      <li><a href="#pretrained-weights-2">Pretrained Weights</a></li>
    </ul>
  </li>
</ul>

<h2 id="data-source">Data Source</h2>

<h3 id="datasets">Datasets</h3>

<p>Even before anyone can think about making a predictive model, there is a need to identify and obtain a good source of data which will be used to train and test the model. Since our project is concerned with video frames prediction, it is very obvious that the model would need a lot of videos to get something meaningful out of it so that given a frame, the model is trained well enough to predict the future frames.</p>

<p>We use the famous UCF-101 dataset for training the model. It is currently the largest dataset of human actions. They consist of 101 action classes and over 13k clips and 27 hours of video data. The classes describe different human actions which have been uploaded by the users containing camera motion and cluttered background.</p>

<p>Because some of the categories in the UCF-101 dataset have very little movement, we removed such categories altogether from the dataset. This identification was done using L2 distance between consecutive frames. (Ask what to write here)</p>

<h3 id="preprocessing-the-input">Preprocessing the input</h3>
<p>The model works well when the data lies within the same range and so, the pixel values for all of the video frames in each of the video are transformed to somewhere between <code class="highlighter-rouge">[-1,1]</code>. To achieve this, each of the video , say X, is preprocessed using the formula X = (X - 127.5) / 127.5 instead of providing the raw video as input.</p>

<h3 id="postprocessing-the-input">Postprocessing the input</h3>
<p>Because the model uses a tanh function at the end, the output generated by the model has pixel values lying in between <code class="highlighter-rouge">[-1,1]</code>. This output undergoes postprocessing so as to generate video frames. Say, the model produces a frame X, X is postprocessed using the formula X = X * 127.5 + 127.5.</p>

<h3 id="batch-generation">Batch Generation</h3>
<p>Each batch consists of a certain number of videos and each video consists of a certain number of frames. The starting frame for each such video in a batch is selected randomly. For example, if the batch contains 4 videos and each video contains 4 continuous frames then, say for video-1 in the batch, we first generate a random number between <code class="highlighter-rouge">[0,1,2,3,...,(N-1)-4]</code> where video-1 contains N frames and each video in the batch requires 4 continuous frames. Say we generate the number <code class="highlighter-rouge">18</code>, then the frames <code class="highlighter-rouge">18, 19, 20, 21</code> become the input for video-1 in the current batch. Similar selection logic follows for other videos in the batch.</p>

<h3 id="selection-at-an-interval">Selection at an interval</h3>
<p>While working with the way the videos were getting generated till now, it was observed that there was hardly any movement in the actual video due to which even the predicted video was very static. In order to overcome this, we came up with an approach of selecting video frames with a certain interval in between the selected frames rather than having continuous frames. Let’s take the same example as above. Say we generate the number <code class="highlighter-rouge">18</code> and suppose we are using an interval of <code class="highlighter-rouge">4</code> frames, then the frames <code class="highlighter-rouge">18, 22, 26, 30</code> are selected as input for video-1 in the current batch. The reasoning behing this is that taking frames at an interval will have more movement rather than continuous frames and therefore, the model will be able to capture the actual movement well and will thus generate videos with movements rather than generating a static video.</p>

<h2 id="sequence-to-sequence-model">Sequence to Sequence Model</h2>

<h3 id="architecture">Architecture</h3>
<p>To speak in simple terms, a sequence to sequence model takes in a sequence of inputs, looks and observes at each input element in the sequence and then tries to predict the next element of the sequence. At a high level, it contains an encoder and a decoder as its main components. The encoder part of the model converts an input sequence (such as a sequence of video frames) into a fixed representation. The decoder part of the model is then trained on both the output sequence along with the fixed representation generated by the encoder. The decoder can therefore make more intelligent predictions about future frames based on the current frame as well as using the encoded representation from the encoder.</p>

<p>The encoder and decoder part of the model is created by using an LSTM Convolutional cell with a Convolutional layer below it and a Deconvolutional layer above it (only for the decoder part). In the encoder part, a Covolutional layer takes a raw video frame as input and passes its representation of the frame to an LSTM Convolutional cell. This hidden state is then propogated throughout the LSTM stack. In the decoder part, the output of decoder at each timestep becomes the input to the decoder at the next time step. This input is passed through a Convolutional layer whose output is then passed to an LSTM Convolutional cell just like the encoder with the only difference that the output generated by LSTM Convolutional cell is passed through a Deconvolutional layer which generates the predicted frame. Again, this predicted frame is passed as an input to the next decoder cell.</p>

<p>The specification for each of the Convolutional and Deconvolutional layer is the same as explained previously in the Vanilla Convolutional LSTM model (Insert URL here for Vanilla Convolutional LSTM model). The model takes in 4 frames as input and tries to predict the next 4 frames in the sequence as the output.</p>

<p><img src="img/seq2seq/graphs/Sequence_Testing.gif" alt="Seq2Seq_Train" /></p>

<h3 id="training-and-testing">Training and Testing</h3>
<p>For training, we use a batch size of 16 videos with 4 frames each as input on the encoder side. On the decoder side, the actual next 3 frames of each of those 16 videos is passed as input while the output obtained from the decoder is used to calculate the loss and improve the model predictions.</p>

<p>For testing, we again use a batch size of 16 videos with 4 frames each as input on the encoder side. While, on the decoder side, the output generated by the previous decoder cell is used as an input for the next decoder cell.</p>

<h3 id="graphs">Graphs</h3>
<p><img src="img/seq2seq/graphs/seq2seq.png" alt="Seq2Seq_Train" /></p>

<h3 id="results">Results</h3>
<p><img src="img/seq2seq/results/v_Swing_g13_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Swing_g13_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_MilitaryParade_g20_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_MilitaryParade_g20_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingSpeedBag_g10_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingSpeedBag_g10_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_RockClimbingIndoor_g05_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_RockClimbingIndoor_g05_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TaiChi_g15_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TaiChi_g15_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_WritingOnBoard_g19_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_WritingOnBoard_g19_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingPiano_g19_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingPiano_g19_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_YoYo_g05_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_YoYo_g05_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BalanceBeam_g10_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BalanceBeam_g10_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FloorGymnastics_g05_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FloorGymnastics_g05_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_RopeClimbing_g20_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_RopeClimbing_g20_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PoleVault_g24_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PoleVault_g24_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_UnevenBars_g02_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_UnevenBars_g02_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JumpingJack_g01_c07_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JumpingJack_g01_c07_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketBowling_g20_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketBowling_g20_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PushUps_g11_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PushUps_g11_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Hammering_g22_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Hammering_g22_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HorseRace_g07_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HorseRace_g07_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TableTennisShot_g12_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TableTennisShot_g12_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_GolfSwing_g20_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_GolfSwing_g20_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CleanAndJerk_g01_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CleanAndJerk_g01_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Lunges_g09_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Lunges_g09_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FrontCrawl_g22_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FrontCrawl_g22_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingDaf_g10_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingDaf_g10_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PizzaTossing_g22_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PizzaTossing_g22_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Skijet_g05_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Skijet_g05_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingDhol_g04_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingDhol_g04_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BaseballPitch_g03_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BaseballPitch_g03_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TrampolineJumping_g19_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_TrampolineJumping_g19_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_VolleyballSpiking_g03_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_VolleyballSpiking_g03_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HighJump_g01_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HighJump_g01_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingPunchingBag_g12_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingPunchingBag_g12_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HammerThrow_g21_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HammerThrow_g21_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingGuitar_g25_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingGuitar_g25_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Shotput_g18_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Shotput_g18_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_ParallelBars_g09_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_ParallelBars_g09_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_WallPushups_g11_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_WallPushups_g11_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JugglingBalls_g06_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JugglingBalls_g06_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CliffDiving_g04_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CliffDiving_g04_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BasketballDunk_g25_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BasketballDunk_g25_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingTabla_g16_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingTabla_g16_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Rafting_g13_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Rafting_g13_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PullUps_g11_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PullUps_g11_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Fencing_g17_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Fencing_g17_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketBowling_g11_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketBowling_g11_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Rowing_g02_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Rowing_g02_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Surfing_g17_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Surfing_g17_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HulaHoop_g04_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HulaHoop_g04_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BandMarching_g05_c07_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BandMarching_g05_c07_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SoccerJuggling_g07_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SoccerJuggling_g07_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingSitar_g21_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingSitar_g21_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingFlute_g19_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingFlute_g19_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BasketballDunk_g12_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BasketballDunk_g12_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SoccerPenalty_g10_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SoccerPenalty_g10_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingPunchingBag_g19_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BoxingPunchingBag_g19_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_IceDancing_g16_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_IceDancing_g16_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Skiing_g23_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Skiing_g23_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BreastStroke_g23_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BreastStroke_g23_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Nunchucks_g15_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Nunchucks_g15_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JumpRope_g23_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JumpRope_g23_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkateBoarding_g07_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkateBoarding_g07_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FieldHockeyPenalty_g22_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FieldHockeyPenalty_g22_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingViolin_g05_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingViolin_g05_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HorseRiding_g25_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_HorseRiding_g25_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Kayaking_g23_c06_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Kayaking_g23_c06_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkyDiving_g15_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkyDiving_g15_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PommelHorse_g13_c04_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PommelHorse_g13_c04_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FrisbeeCatch_g05_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_FrisbeeCatch_g05_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JavelinThrow_g09_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_JavelinThrow_g09_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_ThrowDiscus_g18_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_ThrowDiscus_g18_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Typing_g20_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Typing_g20_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketShot_g06_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_CricketShot_g06_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Drumming_g16_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_Drumming_g16_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_StillRings_g21_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_StillRings_g21_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingCello_g24_c05_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_PlayingCello_g24_c05_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SalsaSpin_g24_c02_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SalsaSpin_g24_c02_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SumoWrestling_g17_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SumoWrestling_g17_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkyDiving_g04_c01_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_SkyDiving_g04_c01_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BodyWeightSquats_g13_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_BodyWeightSquats_g13_c03_generated_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_MoppingFloor_g04_c03_expected_large.gif" alt="seq2seq_results" />
<img src="img/seq2seq/results/v_MoppingFloor_g04_c03_generated_large.gif" alt="seq2seq_results" /></p>

<h3 id="advantages">Advantages</h3>

<p>This model able to capture motion of frames and color of steady background in the video.</p>

<h3 id="model-tweaks">Model tweaks</h3>
<p>On top of the baseline model as described above we tried the following tweaks as an attempt to improve performance.
Here is a quick summary of what we tried along with the intuition behind them:</p>

<ul>
  <li>Teacher Forcing: We decided to remove teacher forcing from above model
during training so that each unit sums correct teacher activations as input for the next iteration instead of only summing activations from incoming units.</li>
  <li>Batch Normalization: After training the above model, we found that the capacity of the network was not enough to make good predictions.
Therefore, we increased number of Conv-Deconv layers and
introduced a Batch Normalization layer.</li>
</ul>

<h3 id="problems">Problems</h3>

<p>Seq2Seq model is not able to capture motion very well. Overall image becomes blur and specially become more blur where motion happens. Another major problem is this model can not be scaled for large images as it is has Conv-LSTM cells in middle of Conv and DeConv layer. Conv-LSTM cells has fixed memory and we cannot run larger sized images at test time.</p>

<h3 id="pretrained-weights">Pretrained Weights</h3>

<p><br /></p>

<h2 id="autoencoder-model">Autoencoder Model</h2>

<h3 id="architecture-1">Architecture</h3>
<p>An autoencoder model is used for unsupervised learning in which the model tries to reconstruct the input so that the generated output is as similar as possible to the given input. Basically, it tries to copy its input to its output. At a high level, there are 2 symmetrical parts to an autoencoder - an encoder part and a decoder part. The encoder part of the network takes in raw images/video frames as input and tries to generate a vector representation or an encoding for the given input. The decoder part of the network takes this encoding of the input and tries to reconstruct the output as similar as possible to the input.</p>

<p>In our case, we make the decoder generate the next video frame given the current video frame instead of reconstructing the same input video frame. Also, The corresponding convolutional and deconvolutional layers are connected together by making use of skip connections. Each of the video frames has some spatial information associated with itself. The skip connections help in maintaining better spatial information.</p>

<p>The encoder portion of the autoencoder takes an input video frame and uses a feature map with the configuration as <code class="highlighter-rouge">[32, 64, 128, 256, 512]</code> while the decoder portion of the autoencoder uses the same feature map, but in the reverse order i.e. <code class="highlighter-rouge">[512, 256, 128, 64, 32]</code> and finally generates the output video frame which is supposed to be the generated next video frame.</p>

<h3 id="training-and-testing-1">Training and Testing</h3>

<p>At the time of training we fed 4 frames as a input and expected next frame predication from the model. Repeated mentioned process for several videos while training.</p>

<p>At testing time we want to predict several images. In this case we will first feed <code class="highlighter-rouge">T0-T3</code> as input and expect to predict <code class="highlighter-rouge">T4</code>. For predication of <code class="highlighter-rouge">T5</code> we will feed <code class="highlighter-rouge">T1-T4</code> where <code class="highlighter-rouge">T4</code> comes from previous predication.</p>

<h3 id="graphs-1">Graphs</h3>
<p><img src="img/skip_autoencoder/graphs/skip_autoencoder.png" alt="skip_autoencoder" /></p>

<h3 id="results-1">Results</h3>

<p><img src="img/skip_autoencoder/results/v_TaiChi_g15_c01_expected_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_TaiChi_g15_c01_generated_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_WritingOnBoard_g19_c03_expected_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_WritingOnBoard_g19_c03_generated_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_PlayingPiano_g19_c04_expected_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_PlayingPiano_g19_c04_generated_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_YoYo_g05_c01_expected_large.gif" width="210" />
<img src="img/skip_autoencoder/results/v_YoYo_g05_c01_generated_large.gif" width="210" /></p>

<h3 id="advantages-1">Advantages</h3>

<p>This model can work independent of shape of the image. This model is based fully on Convolutional layer and therefore at testing time we can feed image of different sizes compared to training time. This model also capture motion and predict more sharper images than previous model.</p>

<h3 id="model-tweaks-1">Model tweaks</h3>
<p>In the autoencoder model we tried adding symmetric skip connections as described <a href="https://arxiv.org/pdf/1606.08921.pdf">here</a>. The goal was to have a very powerful decoder with information flowing from encoder with the help of symmetric skip connections.</p>

<h3 id="problems-1">Problems</h3>

<p>This model becomes blur more quickly. Steady background doesn’t get blur as compared to previous model. Model blurs the part where motion happens.</p>

<h3 id="pretrained-weights-1">Pretrained Weights</h3>

<p><br /></p>

<h2 id="multi-scale-model">Multi-Scale Model</h2>

<h3 id="architecture-2">Architecture</h3>
<p>Multi scale architecture model is based on idea of predicating small resolution image and resoluting the predicated image as model goes deeper. This model predicts one image at a time as opposed to seq2seq model where in one shot 4-8 images are predicated by LSTM. Multi-Scale model expects input in different form, so we will begin our discussion by describing input requirements.</p>

<p>For sake of example, lets say we have given 4 frames and we are trying to predict next 4 frames, i.e. images are given from <code class="highlighter-rouge">t0-t3</code> (each having <code class="highlighter-rouge">H,W</code> as heigth and width, in our case <code class="highlighter-rouge">64x64</code>) and model is trying predict <code class="highlighter-rouge">t4-t7</code>. Here we have 4 images and each has channel <code class="highlighter-rouge">RGB</code> (3 channels). In seq2seq model we feed this images one by one as we loop through LSTM cells, here instead we will feed all <code class="highlighter-rouge">4</code> images in one shot. Now question comes to your mind how we will do this? Pile up all <code class="highlighter-rouge">4</code> images on top of each other like we do with playing cards or plates on stack/shelf. If we have 4 images with 3 channels each, you can think of them having 1 image of 12 channels i.e. <code class="highlighter-rouge">4 images x 3 channels = 12</code>. Lets call this new image as <code class="highlighter-rouge">I0</code>. Please note that <code class="highlighter-rouge">I</code> image will have same <code class="highlighter-rouge">H,W</code> as the original image.</p>

<p><img src="img/multi_scale_GAN/graphs/Multi_scale_GAN.gif" alt="MultiScale_Input" /></p>

<p>In clothing as we see in shopping mall, same shirt has different sizes like xsmall (<code class="highlighter-rouge">XS</code>), small (<code class="highlighter-rouge">S</code>), medium (<code class="highlighter-rouge">M</code>), large (<code class="highlighter-rouge">L</code>), etc. We will do same with our image. Lets create 4 different shapes of same image. Currently our <code class="highlighter-rouge">I</code> is <code class="highlighter-rouge">64x64x12</code>. Let’s create different shapes as <code class="highlighter-rouge">I_XS</code>, <code class="highlighter-rouge">I_S</code>, <code class="highlighter-rouge">I_M</code>, <code class="highlighter-rouge">I_L</code> having sizes <code class="highlighter-rouge">4x4x12</code>, <code class="highlighter-rouge">16x16x12</code>, <code class="highlighter-rouge">32x32x12</code>, <code class="highlighter-rouge">64x64x12</code>.</p>

<p>This model has mutiple stages, as game having multiple levels. Lets say we have 4 stages in our model (same as number of available shapes). <code class="highlighter-rouge">Stage 1</code> take input of <code class="highlighter-rouge">4x4x12</code> i.e. <code class="highlighter-rouge">I_XS</code> and pass through convolutional layers an gives output of shape <code class="highlighter-rouge">4x4x3</code> i.e. new image predication zeroth output <code class="highlighter-rouge">O_XS</code>.</p>

<p><code class="highlighter-rouge">Stage 2</code> will take input from output of <code class="highlighter-rouge">Stage 1</code> (<code class="highlighter-rouge">O_XS</code>) and <code class="highlighter-rouge">I_S</code>. Firstly, we will reshape <code class="highlighter-rouge">Stage 1</code> output to shape of <code class="highlighter-rouge">I_S</code>. In this case predicated <code class="highlighter-rouge">O0_XS</code> (<code class="highlighter-rouge">4x4x3</code>) will be reshaped to <code class="highlighter-rouge">16x16x3</code> (input shape of <code class="highlighter-rouge">I_S</code>). Now concatenate this new reshaped input with <code class="highlighter-rouge">I_S</code> at channel axis. <code class="highlighter-rouge">I_S</code> (<code class="highlighter-rouge">16x16x12</code>) concatenated with <code class="highlighter-rouge">16x16x3</code> to form <code class="highlighter-rouge">16x16x15</code> (12 channels from <code class="highlighter-rouge">I_S</code> +3 channels from <code class="highlighter-rouge">O_XS</code>). Each stage input will be passed through multiple convolutional layers.</p>

<p><img src="img/multi_scale_GAN/graphs/Multi_Scale_Processing.gif" alt="MultiScale_Architecture" /></p>

<p>As we saw for <code class="highlighter-rouge">Stage 2</code> is taking scaled-up inputs from <code class="highlighter-rouge">Stage 1</code> and reshaped actual input. We will do same thing for <code class="highlighter-rouge">Stage 3</code> and <code class="highlighter-rouge">Stage 4</code> where we take input from previous stage output and reshaped input. (<code class="highlighter-rouge">Stage 1</code> doesnot take any previous input.) Final output generated at each layer will be <code class="highlighter-rouge">O_XS</code> (<code class="highlighter-rouge">4x4x3</code>),<code class="highlighter-rouge">O_S</code> (<code class="highlighter-rouge">16x16x3</code>), <code class="highlighter-rouge">O_M</code> (<code class="highlighter-rouge">32x32x3</code>) , <code class="highlighter-rouge">O_L</code> (<code class="highlighter-rouge">64x64x3</code>) respectively.</p>

<p>Now we will reshape expected image same as we done for input image, in this case we will have 4 different shaped expected image (<code class="highlighter-rouge">E_XS</code>,<code class="highlighter-rouge">E_S</code>,<code class="highlighter-rouge">E_M</code>,<code class="highlighter-rouge">E_L</code>). Lets out loss function is <code class="highlighter-rouge">L(.,.)</code>. We will calculated loss as sum of loss at each predicated layer i.e. <code class="highlighter-rouge">L(E_XS, O_XS) + L(E_S, O_S) + L(E_M, O_M) + L(E_L, O_L)</code>. In our case we are <code class="highlighter-rouge">L(.,.)</code> is <code class="highlighter-rouge">l2</code> and <code class="highlighter-rouge">GDL</code> loss. <code class="highlighter-rouge">L2</code> is pixel wise euclidean distance between predicated and actual image. <code class="highlighter-rouge">GDL</code> loss calculates <code class="highlighter-rouge">| |P4 - P1| - |E4 - E1| |</code> (as shown in below image)</p>

<p>Now lets make this architecture more exiciting by introducing <strong>Generative Adverserial Network (GAN) to this model</strong>. Generator of GAN model is same as model explained above. Discriminator model will be same as generator but with some additional changes. Now in Discriminator at each stage after predicating output (of shape as equal to image), we will flatten that output and connect fully connected layer in front of it. Final output will be single value showing how it is real/fake. At 4 stages we will have 4 of this value indicating at each layer how generator is doing in terms of mimicking the real next frame. Loss calculation is now sum of <code class="highlighter-rouge">l2</code>, <code class="highlighter-rouge">GDL</code> and <code class="highlighter-rouge">Discriminator loss</code>.</p>

<h3 id="model-twicks">Model twicks</h3>

<p>We tried multi scale setting without GAN model, i.e. we tried to optimize loss solely based on generator part of GAN. In other case we tried to predict 4 and 8 time frame preications. We also tried L2 loss but results are getting blur if we just use L2 loss (without GDL loss) optimization as it goes toward predication of mean.</p>

<h3 id="training-and-testing-2">Training and Testing</h3>

<p>At training time we feed 4 images <code class="highlighter-rouge">T0-T3</code>, each having 4 different resolutions like <code class="highlighter-rouge">4x4</code>, <code class="highlighter-rouge">16x16</code>, <code class="highlighter-rouge">32x32</code> and <code class="highlighter-rouge">64x64</code>. In total we feed 4 (<code class="highlighter-rouge">T0-T3</code>) x 4 (different resolutions) = 16 frames. We expect <code class="highlighter-rouge">T4</code> predication in 4 different above mentioned resolution. We trained this setting for several video at different starting times.</p>

<p>At testing time (same as skip autoencoder) we feed 4 images and predict one frame. For next frame we remove oldest frame <code class="highlighter-rouge">T0</code> and add new predicated frame <code class="highlighter-rouge">T4</code> to feed to graph.</p>

<h3 id="graphs-2">Graphs</h3>

<p><img src="img/multi_scale_GAN/graphs/model_running/0.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/1.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/2.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/3.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/4.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/5.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/7.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/8.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/9.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/10.png" alt="MultiScale_model_running" />
<img src="img/multi_scale_GAN/graphs/model_running/11.png" alt="MultiScale_model_running" /></p>

<h3 id="results-2">Results</h3>
<p><img src="img/multi_scale_GAN/results/v_WritingOnBoard_g19_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_WritingOnBoard_g19_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_VolleyballSpiking_g03_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_VolleyballSpiking_g03_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_YoYo_g05_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_YoYo_g05_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CleanAndJerk_g01_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CleanAndJerk_g01_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BalanceBeam_g10_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BalanceBeam_g10_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PoleVault_g24_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PoleVault_g24_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BodyWeightSquats_g13_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BodyWeightSquats_g13_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_MoppingFloor_g04_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_MoppingFloor_g04_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingDhol_g04_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingDhol_g04_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_UnevenBars_g02_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_UnevenBars_g02_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_TaiChi_g15_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_TaiChi_g15_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PushUps_g11_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PushUps_g11_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Hammering_g22_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Hammering_g22_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HorseRace_g07_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HorseRace_g07_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_GolfSwing_g20_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_GolfSwing_g20_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Lunges_g09_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Lunges_g09_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingDaf_g10_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingDaf_g10_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PizzaTossing_g22_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PizzaTossing_g22_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Skijet_g05_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Skijet_g05_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HighJump_g01_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HighJump_g01_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HammerThrow_g21_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HammerThrow_g21_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingGuitar_g25_c06_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingGuitar_g25_c06_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_ParallelBars_g09_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_ParallelBars_g09_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_WallPushups_g11_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_WallPushups_g11_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_FrisbeeCatch_g05_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_FrisbeeCatch_g05_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CricketBowling_g11_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CricketBowling_g11_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SoccerJuggling_g07_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SoccerJuggling_g07_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingSitar_g21_c06_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingSitar_g21_c06_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BasketballDunk_g12_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BasketballDunk_g12_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SoccerPenalty_g10_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SoccerPenalty_g10_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Skiing_g23_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Skiing_g23_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Nunchucks_g15_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Nunchucks_g15_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_JumpRope_g23_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_JumpRope_g23_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SkateBoarding_g07_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SkateBoarding_g07_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SkyDiving_g15_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SkyDiving_g15_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingViolin_g05_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingViolin_g05_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HorseRiding_g25_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HorseRiding_g25_c03_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_TableTennisShot_g12_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_TableTennisShot_g12_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PommelHorse_g13_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PommelHorse_g13_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_JavelinThrow_g09_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_JavelinThrow_g09_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_ThrowDiscus_g18_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_ThrowDiscus_g18_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Typing_g20_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Typing_g20_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CricketShot_g06_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_CricketShot_g06_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Surfing_g17_c06_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Surfing_g17_c06_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_StillRings_g21_c01_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_StillRings_g21_c01_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingCello_g24_c05_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_PlayingCello_g24_c05_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SalsaSpin_g24_c02_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SalsaSpin_g24_c02_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Rowing_g02_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_Rowing_g02_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HulaHoop_g04_c04_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_HulaHoop_g04_c04_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BandMarching_g05_c07_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_BandMarching_g05_c07_generated_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SumoWrestling_g17_c03_expected_large.gif" alt="multi_scale_gan8_results" />
<img src="img/multi_scale_GAN/results/v_SumoWrestling_g17_c03_generated_large.gif" alt="multi_scale_gan8_results" /></p>

<h3 id="advantages-2">Advantages</h3>

<p>Multi Scale model is pretty well in captioning motion and predicating next frames. This model also fully based on convolution and therefore works with any shape of images at run time. Due to trained on GAN settings this model predict next frames which looks closer to real images.</p>

<h3 id="problems-2">Problems</h3>

<p>This model fails for video contains much more notion and this can be come because UCF-101 dataset videos has less movement. This model try to predict pixels from scratch which cause blurness for longer sequences.</p>

<h3 id="pretrained-weights-2">Pretrained Weights</h3>

<h2 id="evaluation">Evaluation</h2>

<p>We evalualted models on 5 different criteria as follows Sharpness, Peak Signal to Noise Ratio (PSNR), L2, GDL and Total loss. Sharpness of image is tells about how results blur vs sharper edges on images. PSNR indicates about good image reconstruction is happening. L2 loss takes pixel wise square loss to check how far predication is from actual image. GDL loss calculates difference with surrondings pixel to focus on local changes rather than global changes. Total loss is addition of L2, GDL loss. Total loss also contains sum of discriminator loss in case of GAN models.</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Team Pragmatic Chaos Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Team Pragmatic Chaos Blog</li>
          <li><a href="mailto:kabara@usc.edu">kabara@usc.edu</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/team-pragmatic-chaos"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">team-pragmatic-chaos</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Deep Videos (CSCI 599 Project)
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
