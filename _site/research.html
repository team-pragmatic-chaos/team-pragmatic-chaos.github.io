<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Research</title>
  <meta name="description" content="This project aims to bring static photos to life by learning the dynamics of a given scene.">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/research.html">
  <link rel="alternate" type="application/rss+xml" title="CSCI 599 Deep Learning - Deep Videos" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">CSCI 599 Deep Learning - Deep Videos</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
          
            
            
            <a class="page-link" href="/research.html">Research</a>
            
          
            
            
            <a class="page-link" href="/timeline.html">Timeline</a>
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Research</h1>
  </header>

  <div class="post-content">
    <div class="post-content">
  <div class="post-content">
  <p>Table of Contents:</p>
  <ul>
    <li>
      <a href="#dataset">Dataset</a>
      <ul>
        <li>
          <a href="#ucf_101">UCF - 101</a>
        </li>
        <li>
          <a href="#aslam">Aslan</a>
        </li>
        <li>
          <a href="#vondrick">Vondrick</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="#preprocess">Data Pre-processing</a>
    </li>
    <li>
      <a href="#models">Models</a>
      <ul>
        <li>
          <a href="#vanilla">Vanilla Convolution LSTM</a>
          <ul>
            <li>
              <a href="#input_vanilla">Input</a>
            </li>
            <li>
              <a href="#train_vanilla">Training</a>
            </li>
            <li>
              <a href="#test_vanilla">Testing</a>
            </li>
            <li>
              <a href="#problem_vanilla">Problems</a>
            </li>
            <li>
              <a href="#output_vanilla">Results</a>
            </li>
          </ul>
        </li>
        <li>
          <a href="#conv-lstm-deconv">Convolution LSTM Deconvolution</a>
        </li>
        <li>
          <a href="#teacher">Teacher Enforcement</a>
        </li>
        <li>
          <a href="#gan">Generative Adversarial Network</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="#output">Result</a>
    </li>
  </ul>

  <p>
    <a name="dataset"></a>
  </p>
  <h2 id="dataset">Dataset</h2>
  <p>"Write about datasets used."</p>

  <p>
    <a name="ucf_101"></a>
  </p>
  <h3 id="ucf_101">UCF - 101</h3>
  <p>UCF101 is a dataset collected from YouTube. It contains over 13,320 realistic action videos, having 101 action categories.</p>
  <p>Diversity of UCF101 is in terms of: 
    <ul>
      <li>
        Actions and diverse camera angles,
      </li>
      <li>
        Poses and object appearance,
      </li>
      <li>
        Light and illumination, and few more.
      </li>
    </ul>
  </p>
  <p>All the 101 action categories of videos are grouped into 25 different groups. The videos that belong to same group, share similar features like background, actions or actors. Each of these groups have more or less 5-7 videos of each category.</p>
  <p>The action classes are divided into following categories:
    <ul>
      <li>
        Human-Object Interaction
      </li>
      <li>
        Body-Motion Only
      </li>
      <li>
        Human-Human Interaction
      </li>
      <li>
        Playing Musical Instruments
      </li>
      <li>
        Sports
      </li>
    </ul>
  </p>
  <p>Detailed description of the dataset can be found <a href="http://crcv.ucf.edu/papers/UCF101_CRCV-TR-12-01.pdf">here.</a></p>

  <p>
    <a name="aslam"></a>
  </p>
  <h3 id="aslam">Aslan</h3>
  <p>"Write about Aslan dataset."</p>

  <p>
    <a name="vondrick"></a>
  </p>
  <h3 id="vondrick">Vondrick</h3>
  <p>"Write about Vondrick dataset."</p>

  <p>
    <a name="preprocess"></a>
  </p>
  <h2 id="preprocess">Data Pre-processing</h2>
  <p>"Write about Data Pre-processing."</p>

  <p>
    <a name="models"></a>
  </p>
  <h2 id="models">Models</h2>
  <p>"Write about Models ."</p>

  <p>
    <a name="vanilla"></a>
  </p>
  <h3 id="vanilla">Vanilla Convolution LSTM</h3>
  <p>LSTM function as a human's understanding. A human persists previous knowledge and tries to understand future events with the help of previous ones. Similarly, Recurrent neural networks function this way. But the problem of long-term dependencies give rise to Long Short Term Memory networks or LSTMs.</p>

  <p>
    <a name="input_vanilla"></a>
  </p>
  <h4 id="input_vanilla">Input</h4>
  <p>Our input <code><span class="n">X</span></code> can be described as a <strong>5</strong> dimensional numpy array:
    <div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">X.shape = (4, 32, 64, 64, 3)</span></code></pre>
    Here,
    <code><span class="n">Batch size = 4</span></code>,
    <code><span class="n">Number of time frames = 32 </span></code>, and
    <code><span class="n">Height of image = 64</span></code>,
    <code><span class="n">Width of image = 64</span></code>,
    <code><span class="n">Number of channels = 3</span></code>.
    </div>
  </p>
  <p>
    <a name="conv-lstm-deconv"></a>
  </p>
  <h3 id="conv-lstm-deconv">Convolution LSTM Deconvolution</h3>
  <p>"Write about Convolution LSTM Deconvolution Model."</p>

  <p>
    <a name="teacher"></a>
  </p>
  <h3 id="teacher">Teacher Enforcement</h3>
  <p>"Write about Teacher Enforcement Model."</p>

  <p>
    <a name="gan"></a>
  </p>
  <h3 id="gan">Generative Adversarial Network</h3>
  <p>"Write about Generative Adversarial Network."</p>

  <p>
    <a name="output"></a>
  </p>
  <h2 id="output">Result</h2>
  <p>"Write about Output Obtained."</p>

</div>

</div>

  </div>

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">CSCI 599 Deep Learning - Deep Videos</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              CSCI 599 Deep Learning - Deep Videos
            
            </li>
            
            <li><a href="mailto:chaospragmatic@gmail.com">chaospragmatic@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/team-pragmatic-chaos"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">team-pragmatic-chaos</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>This project aims to bring static photos to life by learning the dynamics of a given scene.</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
